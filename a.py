from datetime import timedelta
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.models.modelMultiAccountPnL import MultiAccountPnL
from src.models.modelPNL import (
    MultiAccountPnL_M1, MultiAccountPnL_M5, MultiAccountPnL_M10,
    MultiAccountPnL_M15, MultiAccountPnL_M30,
    MultiAccountPnL_H1, MultiAccountPnL_H2, MultiAccountPnL_H4,
    MultiAccountPnL_H6, MultiAccountPnL_H8, MultiAccountPnL_H12,
    MultiAccountPnL_D, MultiAccountPnL_W, MultiAccountPnL_MN,
)
import pandas as pd
import gc
from src.models.model import Base as Base2

# ------------------- Config -------------------
DB_PATH = "sqlite:///./pnl.db"
engine = create_engine(DB_PATH)
SessionLocal = sessionmaker(bind=engine)
session = SessionLocal()

Base2.metadata.create_all(engine)

# ------------------- H√†m t√≠nh aggregate -------------------
def aggregate(df_group):
    open_ = df_group.iloc[0]["total_pnl"]
    close = df_group.iloc[-1]["total_pnl"]
    high = df_group["total_pnl"].max()
    low = df_group["total_pnl"].min()
    P = (close + high + low) / 3
    time = df_group.iloc[-1]["time"]
    login = df_group.iloc[-1]["login"]
    return {
        "login": login,
        "time": time,
        "open": open_,
        "high": high,
        "low": low,
        "close": close,
        "P": P,
    }

# ------------------- C√°c khung th·ªùi gian -------------------
def round_time(df, freq):
    return df.groupby(["login", pd.Grouper(key="time", freq=freq)])

timeframes = {
    "M1": (MultiAccountPnL_M1, "1min"),
    "M5": (MultiAccountPnL_M5, "5min"),
    "M10": (MultiAccountPnL_M10, "10min"),
    "M15": (MultiAccountPnL_M15, "15min"),
    "M30": (MultiAccountPnL_M30, "30min"),

    "H1": (MultiAccountPnL_H1, "1h"),
    "H2": (MultiAccountPnL_H2, "2h"),
    "H4": (MultiAccountPnL_H4, "4h"),
    "H6": (MultiAccountPnL_H6, "6h"),
    "H8": (MultiAccountPnL_H8, "8h"),
    "H12": (MultiAccountPnL_H12, "12h"),

    "W": (MultiAccountPnL_W, "1W"),
    "MN": (MultiAccountPnL_MN, "1ME"),
}

# ------------------- Gom theo "ng√†y trade" (07h‚Äì07h) -------------------
def group_custom_day(df):
    df = df.copy()

    # Chu·∫©n h√≥a timezone VN
    if df["time"].dt.tz is None:
        df["time"] = df["time"].dt.tz_localize("Asia/Bangkok")
    else:
        df["time"] = df["time"].dt.tz_convert("Asia/Bangkok")

    df["shifted_time"] = df["time"] - pd.Timedelta(hours=7)
    df["trade_day"] = df["shifted_time"].dt.date

    def adjust_for_monday(row):
        weekday = row["time"].weekday()
        hour = row["time"].hour
        if weekday == 0 and 4 <= hour < 7:
            return f"{row['time'].date()}_mon_early"
        return str(row["trade_day"])

    df["trade_day"] = df.apply(adjust_for_monday, axis=1)
    return df.groupby(["login", "trade_day"])

# ------------------- H√†m s·ª≠a l·ªói encoding -------------------
def fix_encoding(s):
    if not isinstance(s, str):
        return s
    try:
        # Th·ª≠ decode n·∫øu b·ªã l·ªói cp1252 ‚Üí utf-8
        return s.encode("latin1").decode("utf-8")
    except Exception:
        try:
            # N·∫øu v·∫´n l·ªói th√¨ b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá
            return s.encode("utf-8", "ignore").decode("utf-8")
        except Exception:
            return s

# ------------------- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω theo batch -------------------
print("ƒêang ƒë·ªçc d·ªØ li·ªáu g·ªëc (chia batch 1_000_000 d√≤ng)...")

BATCH_SIZE = 1_000_000
offset = 0
total_processed = 0

while True:
    batch = (
        session.query(MultiAccountPnL)
        .order_by(MultiAccountPnL.id)
        .offset(offset)
        .limit(BATCH_SIZE)
        .all()
    )

    if not batch:
        break

    print(f"\nüü© ƒêang x·ª≠ l√Ω batch {offset} ‚Üí {offset + len(batch)} ({len(batch)} d√≤ng)")

    # Convert batch sang DataFrame
    rows = [{
        "id": d.id,
        "login": d.login,
        "time": d.time,
        "total_pnl": d.total_pnl,
        "num_positions": d.num_positions,
        "by_symbol": d.by_symbol,
    } for d in batch]

    df = pd.DataFrame(rows)
    df["time"] = pd.to_datetime(df["time"])

    # üîß Fix l·ªói encoding c·ªôt login
    df["login"] = df["login"].astype(str).apply(fix_encoding)
    if any("ÔøΩ" in s for s in df["login"]):
        print("‚ö†Ô∏è  C·∫£nh b√°o: C√≥ k√Ω t·ª± l·ªói trong login, ƒë√£ c·ªë g·∫Øng kh√¥i ph·ª•c encoding.")

    # ---- X·ª≠ l√Ω t·ª´ng timeframe (M1‚ÄìMN tr·ª´ D) ----
    for tf_name, (Model, freq) in timeframes.items():
        print(f"  ‚ûú Timeframe: {tf_name} ({freq})...")
        grouped = round_time(df, freq)
        result_rows = [aggregate(g) for _, g in grouped]
        objs = [Model(**r) for r in result_rows]
        session.bulk_save_objects(objs)
        session.commit()
        print(f"     ‚úÖ ƒê√£ ghi {len(objs)} d√≤ng v√†o {Model.__tablename__}")

    # ---- X·ª≠ l√Ω timeframe D ----
    print("  ‚ûú Timeframe D (07h‚Äì07h, t√°ch th·ª© 2)...")
    grouped_d = group_custom_day(df)
    result_rows_d = [aggregate(g) for _, g in grouped_d]
    objs_d = [MultiAccountPnL_D(**r) for r in result_rows_d]
    session.bulk_save_objects(objs_d)
    session.commit()
    print(f"     ‚úÖ ƒê√£ ghi {len(objs_d)} d√≤ng v√†o {MultiAccountPnL_D.__tablename__}")

    # ---- D·ªçn RAM ----
    total_processed += len(batch)
    del df, rows, batch, result_rows, result_rows_d, objs, objs_d
    gc.collect()

    offset += BATCH_SIZE

print(f"\nüéØ Ho√†n t·∫•t x·ª≠ l√Ω to√†n b·ªô d·ªØ li·ªáu ({total_processed:,} d√≤ng)!")
