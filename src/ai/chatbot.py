from langchain.messages import HumanMessage
import os
import requests
from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_classic.chains import RetrievalQA
from langchain_openai import ChatOpenAI

load_dotenv()

# -------------------------------
# 1Ô∏è‚É£ C·∫•u h√¨nh API
# -------------------------------
API_URLS = {
    "pnl": os.getenv("API_PNL_URL"),
    "acc": os.getenv("API_ACC_TRANSACTION_URL"),
}

LOGIN_URL = "http://127.0.0.1:8000/login"
USERNAME = "admin"
PASSWORD = "2Anhem34@123"

def get_new_token():
    """G·ªçi API /login ƒë·ªÉ l·∫•y access_token m·ªõi (chu·∫©n FastAPI OAuth2)."""
    try:
        response = requests.post(
            LOGIN_URL,
            data={  # ‚úÖ ph·∫£i l√† `data` ch·ª© KH√îNG ph·∫£i `json`
                "username": USERNAME,
                "password": PASSWORD
            },
            headers={"Content-Type": "application/x-www-form-urlencoded"},
            timeout=10
        )
        response.raise_for_status()
        data = response.json()
        
        access_token = data.get("access_token") or data.get("token")
        if not access_token:
            raise ValueError(f"Kh√¥ng t√¨m th·∫•y access_token trong ph·∫£n h·ªìi /login: {data}")

        # ‚úÖ C·∫≠p nh·∫≠t bi·∫øn m√¥i tr∆∞·ªùng
        os.environ["API_TOKEN"] = access_token

        # ‚úÖ Ghi ƒë√® v√†o .env ƒë·ªÉ l∆∞u token l√¢u d√†i
        try:
            with open(".env", "r", encoding="utf-8") as f:
                lines = f.readlines()
        except FileNotFoundError:
            lines = []

        with open(".env", "w", encoding="utf-8") as f:
            token_updated = False
            for line in lines:
                if line.startswith("API_TOKEN="):
                    f.write(f"API_TOKEN={access_token}\n")
                    token_updated = True
                else:
                    f.write(line)
            if not token_updated:
                f.write(f"\nAPI_TOKEN={access_token}\n")

        print("üîë ƒê√£ l√†m m·ªõi token th√†nh c√¥ng.")
        return access_token

    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è L·ªói khi k·∫øt n·ªëi API /login: {e}")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi l√†m m·ªõi token: {e}")
    return None

# -------------------------------
# ‚öôÔ∏è B·ªï sung √°nh x·∫° ti·∫øng Vi·ªát ‚Üí param API
# -------------------------------
VN_PARAM_MAP = {
    "m√£": "id_symbol",
    "th∆∞·ªõc": "id_symbol",
    "id": "id_symbol",
    "symbol": "id_symbol",
    "khung": "timeframe",
    "khung_th·ªùi_gian": "timeframe",
    "khung th·ªùi gian": "timeframe",
    "th·ªùi_gian": "timeframe",
    "th·ªùi gian": "timeframe",
    "t·ªëi_ƒëa": "limit",
    "t·ªëi ƒëa": "limit",
    "s·ªë_l∆∞·ª£ng": "limit",
    "s·ªë l∆∞·ª£ng": "limit",
    "gi·ªõi_h·∫°n": "limit",
    "gi·ªõi h·∫°n": "limit",
    "trang": "page",
}

def normalize_vietnamese_param(param):
    key = param.lower().strip().replace(" ", "_")
    return VN_PARAM_MAP.get(key, key)

def fetch_data_from_api(api_name, params=None):
    """G·ªçi API, t·ª± ƒë·ªông refresh token n·∫øu Unauthorized."""
    if api_name not in API_URLS:
        raise ValueError(f"API '{api_name}' ch∆∞a ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.")

    url = API_URLS[api_name]
    token = os.getenv("API_TOKEN")
    headers = {"Authorization": f"Bearer {token}"}

    try:
        response = requests.get(url, params=params, headers=headers)
        response.raise_for_status()
        return response.json()

    except requests.exceptions.HTTPError as e:
        if response.status_code == 401:
            print("‚ö†Ô∏è Token h·∫øt h·∫°n ho·∫∑c kh√¥ng h·ª£p l·ªá. ƒêang l√†m m·ªõi token...")
            new_token = get_new_token()
            if not new_token:
                raise RuntimeError("Kh√¥ng th·ªÉ l√†m m·ªõi token. D·ª´ng ti·∫øn tr√¨nh.")
            # Th·ª≠ g·ªçi l·∫°i API v·ªõi token m·ªõi
            headers["Authorization"] = f"Bearer {new_token}"
            response = requests.get(url, params=params, headers=headers)
            response.raise_for_status()
            return response.json()
        else:
            raise  # C√°c l·ªói kh√°c gi·ªØ nguy√™n

# -------------------------------
# 2Ô∏è‚É£ Kh·ªüi t·∫°o LLM
# -------------------------------
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

# -------------------------------
# 4Ô∏è‚É£ Tr√≠ch xu·∫•t API v√† params t·ª´ c√¢u t·ª± nhi√™n
# -------------------------------
def interpret_user_query(query, llm):
    """D√πng GPT ƒë·ªÉ hi·ªÉu c√¢u ti·∫øng Vi·ªát v√† tr√≠ch API + params."""
    system_prompt = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω gi√∫p √°nh x·∫° c√¢u ti·∫øng Vi·ªát c·ªßa ng∆∞·ªùi d√πng sang l·ªánh API JSON.
H√£y ch·ªâ tr·∫£ v·ªÅ JSON d·∫°ng:
{"api_name": "...", "params": {"id_symbol": "...", "timeframe": "...", "limit": "..."}}

C√°c API h·ª£p l·ªá: pnl, acc.
N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c API n√†o, tr·∫£ v·ªÅ {"api_name": null, "params": {}}.
"""
    full_prompt = f"{system_prompt}\nNg∆∞·ªùi d√πng n√≥i: {query}"
    response = llm.invoke([HumanMessage(content=full_prompt)])

    import json
    try:
        parsed = json.loads(response.content)
        return parsed.get("api_name"), parsed.get("params", {})
    except Exception:
        return None, {}
    
# -------------------------------
# 3Ô∏è‚É£ Ch·∫°y query d·ª±a tr√™n API (ƒë√£ t√≠ch h·ª£p interpret_user_query)
# -------------------------------
def run_api_query(user_query, llm):
    """
    Ph√¢n t√≠ch c√¢u ng∆∞·ªùi d√πng:
      - N·∫øu c√≥ ch·ª©a 'api:' ‚Üí g·ªçi API tr·ª±c ti·∫øp
      - N·∫øu l√† c√¢u t·ª± nhi√™n ‚Üí interpret_user_query ƒë·ªÉ t·ª± hi·ªÉu API & params
    """
    # 1Ô∏è‚É£ N·∫øu user nh·∫≠p d·∫°ng 'api:pnl ...' th√¨ parse th·ªß c√¥ng
    if user_query.lower().startswith("api:"):
        parts = user_query[len("api:"):].strip().split()
        api_name = parts[0]
        params = {}
        for p in parts[1:]:
            if "=" in p:
                k, v = p.split("=", 1)
                params[k] = v
    else:
        # 2Ô∏è‚É£ N·∫øu ng∆∞·ªùi d√πng n√≥i t·ª± nhi√™n ‚Üí d√πng LLM ƒë·ªÉ hi·ªÉu API + params
        api_name, params = interpret_user_query(user_query, llm)
        if not api_name:
            return "‚ùå T√¥i kh√¥ng hi·ªÉu c√¢u n√†y thu·ªôc API n√†o.", None, None

    # 3Ô∏è‚É£ G·ªçi API
    data = fetch_data_from_api(api_name, params)
    if not data:
        return f"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu tr·∫£ v·ªÅ t·ª´ API '{api_name}'.", None, None

    # 4Ô∏è‚É£ Chu·∫©n b·ªã prompt cho LLM ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu
    if isinstance(data, list):
        data_str = "\n".join([str(item) for item in data[:10]])
    else:
        data_str = str(data)

    prompt_text = (
        f"D·ªØ li·ªáu t·ª´ API '{api_name}':\n{data_str}\n\n"
        f"H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu tr√™n:\n{user_query}"
    )

    response = llm.invoke([HumanMessage(content=prompt_text)])
    answer = response.content if hasattr(response, "content") else str(response)

    return answer, api_name, data


# -------------------------------
# 4Ô∏è‚É£ Load Chatbot RetrievalQA
# -------------------------------
def load_chatbot():
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    db = FAISS.load_local("src/ai/vector_db", embeddings, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={"k": 3})
    llm_local = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
    qa = RetrievalQA.from_chain_type(llm=llm_local, retriever=retriever, chain_type="stuff")
    return qa


# -------------------------------
# 5Ô∏è‚É£ Main loop (c√≥ ghi nh·ªõ API g·∫ßn nh·∫•t)
# -------------------------------
if __name__ == "__main__":
    qa = load_chatbot()
    print("ü§ñ Chatbot ƒë√£ s·∫µn s√†ng! G√µ 'exit' ƒë·ªÉ tho√°t.\n")

    last_api_name = None
    last_api_data = None

    while True:
        q = input("üß† B·∫°n: ").strip()
        if q.lower() in ["exit", "quit"]:
            break

        try:
            # N·∫øu l√† l·ªánh g·ªçi API m·ªõi
            if q.lower().startswith("api:"):
                parts = q[len("api:"):].strip().split()
                api_name = parts[0]
                params = {}

                # üîç T·ª± ƒë·ªông parse params t·ª´ c√¢u l·ªánh
                # üîç T·ª± ƒë·ªông parse params (h·ªó tr·ª£ c·∫£ ti·∫øng Vi·ªát)
                for p in parts[1:]:
                    if "=" in p:
                        k, v = p.split("=", 1)
                        k = normalize_vietnamese_param(k)
                        params[k] = v
                    else:
                        # Cho ph√©p vi·∫øt ki·ªÉu: khung th·ªùi_gian M1
                        idx = parts.index(p)
                        if idx + 1 < len(parts) and "=" not in parts[idx + 1]:
                            key = normalize_vietnamese_param(p)
                            params[key] = parts[idx + 1]
                # for p in parts[1:]:
                #     if "=" in p:
                #         k, v = p.split("=", 1)
                #         params[k] = v
                #     else:
                #         # Cho ph√©p vi·∫øt ki·ªÉu: page 1 limit 200
                #         idx = parts.index(p)
                #         if idx + 1 < len(parts) and "=" not in parts[idx + 1]:
                #             params[p] = parts[idx + 1]

                # N·∫øu ng∆∞·ªùi d√πng kh√¥ng nh·∫≠p page/limit -> m·∫∑c ƒë·ªãnh
                params.setdefault("page", "1")
                params.setdefault("limit", "100")
                
                ans, last_api_name, last_api_data = run_api_query(q, llm)
                # ans, last_api_name, last_api_data = run_api_query(api_name, params, "Ph√¢n t√≠ch d·ªØ li·ªáu n√†y gi√∫p t√¥i", llm)
                print("ü§ñ Tr·∫£ l·ªùi:", ans)
                continue

            # N·∫øu h·ªèi ti·∫øp sau API tr∆∞·ªõc ƒë√≥
            elif last_api_data is not None:
                data_str = (
                    "\n".join([str(item) for item in last_api_data[:10]])
                    if isinstance(last_api_data, list)
                    else str(last_api_data)
                )
                prompt_text = (
                    f"Ti·∫øp t·ª•c ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu g·∫ßn nh·∫•t t·ª´ API '{last_api_name}':\n{data_str}\n\n"
                    f"C√¢u h·ªèi m·ªõi: {q}"
                )
                response = llm.invoke([HumanMessage(content=prompt_text)])
                ans = response.content if hasattr(response, "content") else str(response)
                print("ü§ñ Tr·∫£ l·ªùi:", ans)
                continue

            # N·∫øu kh√¥ng c√≥ API tr∆∞·ªõc ƒë√≥ ‚Üí d√πng RetrievalQA
            else:
                result = qa.invoke({"query": q})
                ans = result["result"]
                print("ü§ñ Tr·∫£ l·ªùi:", ans)

        except Exception as e:
            print("‚ö†Ô∏è L·ªói:", e)

